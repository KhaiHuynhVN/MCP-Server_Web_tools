# Web_mcp - MCP Web Tools Server Context

## üìã PROJECT OVERVIEW
- **Project Name**: Web_mcp  
- **Type**: MCP (Model Context Protocol) Server
- **Purpose**: Provide web tools (search, fetch) for AI assistants
- **Current Status**: Web Search tool completed and tested ‚úÖ
- **Timeline**: Reviewed and tested in August 2025

## üèóÔ∏è ARCHITECTURE & FILE STRUCTURE

### Main Server
- `mcp_server.py` - FastMCP server entry point, tool registration
- `pyproject.toml` - Python package configuration
- `README.md` - Project documentation

### Web Search Tool (`/tools/mcp_web_search/`)
- `__init__.py` - Package exports (web_search_tool, get_tool_description)
- `core.py` - Main business logic, API orchestration
- `google_api.py` - Google Custom Search API client implementation  
- `constants.py` - Configuration (API keys, settings)

### Web Fetch Tool (`/tools/mcp_web_fetch/`)
- `__init__.py` - Package exports (web_fetch_tool, get_tool_description)
- `core.py` - Main business logic, URL processing, batch handling
- `fetch_api.py` - HTTP client with BeautifulSoup content extraction
- `constants.py` - Configuration (timeouts, headers, content limits)

## üîß WEB SEARCH TOOL SPECIFICATIONS

### Core Functionality
- **Purpose**: Google search with structured URL results
- **Input**: Search query + optional language parameter
- **Output**: JSON with ~15 ranked results (title, URL, snippet, source)
- **API**: Google Custom Search API integration
- **Languages**: Multi-language support (en, vi, ja, etc.)

## üîß WEB FETCH TOOL SPECIFICATIONS

### Core Functionality - EXTREME SCALE
- **Purpose**: Fetch and extract complete content from URLs
- **Input**: Single URL or list of URLs (max 50 per request - MASSIVE batch processing)
- **Output**: JSON with pure text content (title, description, complete main text, links)
- **Content Types**: HTML, JSON, XML, plain text, RSS/Atom feeds, CSS, JavaScript, CSV
- **Features**: Complete content extraction, smart filtering, context optimization

### Technical Implementation - Web Search
```python
# Main function signature
web_search_tool(query: str, language: str = "en") -> str

# Output format
{
  "query": "search terms",
  "total_results": 15,
  "results": [
    {
      "rank": 1,
      "title": "Page title",
      "url": "https://example.com",
      "snippet": "Description text...", 
      "source": "example.com"
    }
  ],
  "status": "success",
  "message": "T√¨m th·∫•y X k·∫øt qu·∫£ cho 'query'"
}
```

### Technical Implementation - Web Fetch (EXTREME SCALE)
```python
# Main function signature
web_fetch_tool(url: Union[str, List[str]], extract_links: bool = True) -> str

# EXTREME LIMITS Configuration:
MAX_CONTENT_SIZE = 500MB        # Handle massive technical docs
REQUEST_TIMEOUT = 300s          # 5-minute processing time
MAX_EXTRACTED_TEXT = 2M chars   # Complete documentation extraction
MAX_URLS_PER_REQUEST = 50       # Massive batch processing
MAX_LINKS_EXTRACTED = 100       # Complete site mapping

# Context-Optimized Output Format
{
  "total_urls": 1,
  "successful_fetches": 1,
  "results": [
    {
      "url": "https://example.com",
      "title": "Complete Page Title",
      "description": "Meta description...",
      "content": "COMPLETE pure text content (up to 2M chars) - no HTML tags, no ads, no binary data",
      "content_type": "text/html",
      "word_count": 50000,
      "links": [100 extracted links],
      "status": "success"
    }
  ],
  "status": "success"
}
```

### Context Efficiency Features
- **Pure Text Output**: No HTML tags, no binary data (base64), no multimedia
- **Smart Content Filtering**: Removes ads, navigation, forms, videos, scripts
- **Whitespace Optimization**: Clean formatting for AI processing
- **Complete Content**: Up to 2M characters of main content (not snippets)

### Error Handling
- Input validation (query required, string type)
- Network timeout protection (10s)
- API error handling with meaningful messages
- Graceful degradation with status indicators

### Performance Features - Web Search
- **Pagination**: Automatic handling of Google API 10-result limit
- **Max Results**: 15 optimal results (quality over quantity)
- **Domain Extraction**: Clean source domain parsing
- **Response Format**: Consistent JSON structure

### Performance Features - Web Fetch (EXTREME SCALE)
- **Massive Content**: 500MB file processing capability
- **Long Processing**: 5-minute timeout for complex sites
- **Batch Processing**: 50 URLs per request for comprehensive research
- **Complete Extraction**: 2M characters per page (full technical documentation)
- **Smart Retry**: 5 attempts with progressive delays for reliability
- **Content Optimization**: Pure text output, no context waste

## üéØ TESTING SUMMARY (August 2025)

### Web Search Tool - Verified Production Ready
‚úÖ **Search Quality**: 15 relevant results per query from authoritative sources  
‚úÖ **Timeline Accuracy**: Current with 2025 data (ES2025, React 19, Node.js 22)  
‚úÖ **Performance**: Fast response times v·ªõi proper error handling  
‚úÖ **Output Format**: Consistent JSON v·ªõi ranking, snippets, source domains

## üõ†Ô∏è CONFIGURATION

### Google API Setup
- **File**: `constants.py`
- **Required**: GOOGLE_API_KEY, GOOGLE_SEARCH_ENGINE_ID
- **Current Status**: Configured and functional
- **Limits**: Standard Google Custom Search API quotas

### Server Configuration  
- **Transport**: stdio (for MCP protocol)
- **Framework**: FastMCP
- **Port**: Default MCP server setup

## üìä USAGE EXAMPLES

### Web Search Examples
```python
web_search_tool("Python async await best practices")
web_search_tool("JavaScript frameworks 2025", "en")
web_search_tool("React 19 server components tutorial")
```

### Web Fetch Examples (EXTREME SCALE)
```python
# Single technical documentation
web_fetch_tool("https://react.dev/learn/complete-guide")
# ‚Üí Returns: Complete React guide (50,000+ words)

# Massive batch processing
tech_docs = [
    "https://docs.python.org/3/library/",
    "https://developer.mozilla.org/en-US/docs/Web/API/",
    "https://nodejs.org/api/",
    # ... up to 50 URLs
]
web_fetch_tool(tech_docs)
# ‚Üí Returns: Complete technical documentation for all 50 URLs

# Complete API documentation research
web_fetch_tool("https://docs.github.com/en/rest", extract_links=True)
# ‚Üí Returns: Full GitHub API docs + 100 related links
```

### Combined Workflow (COMPREHENSIVE RESEARCH)
```python
# 1. Search for technical documentation
search_results = web_search_tool("TypeScript 5.6 complete documentation")

# 2. Extract top URLs for comprehensive research
urls = [result["url"] for result in search_data["results"][:10]]

# 3. Fetch COMPLETE content from multiple sources
content_results = web_fetch_tool(urls)
# ‚Üí Returns: Complete technical content from 10 sources
# ‚Üí Total: Up to 20M characters of documentation
# ‚Üí Links: Up to 1,000 related resources discovered

# 4. Deep dive into specific areas
specialized_urls = [
    "https://www.typescriptlang.org/docs/handbook/",
    "https://github.com/microsoft/TypeScript/wiki",
    "https://devblogs.microsoft.com/typescript/"
]
detailed_content = web_fetch_tool(specialized_urls)
# ‚Üí Returns: Specialized documentation with complete content
```

## üöÄ DEVELOPMENT STATUS

### Completed ‚úÖ
- [x] Web Search Tool - Full implementation with Google API (15 optimal results)
- [x] Web Fetch Tool - EXTREME SCALE implementation with massive limits
- [x] Error handling and validation for both tools
- [x] Multi-language support (search) & universal content-type support (fetch)
- [x] Context-optimized JSON output formatting
- [x] Comprehensive testing and integration verification
- [x] Complete documentation with extreme capabilities
- [x] **Code Refactoring (Aug 2025)** - Constants centralization
- [x] **MCP Server Integration** - Both tools registered and functional
- [x] **Context Efficiency Optimization** - Pure text output, no binary waste
- [x] **Extreme Limits Configuration** - 500MB, 2M chars, 50 URLs capability

### TODO üìã
- [ ] Enhanced caching mechanisms for massive content
- [ ] Rate limiting for extreme batch processing
- [ ] Additional search engines integration
- [ ] PDF and binary document extraction
- [ ] AI-powered content summarization and analysis
- [ ] Intelligent content chunking for massive documents

## üí° KEY STRENGTHS

1. **Production Quality**: Robust error handling, input validation
2. **Performance**: Efficient API usage with pagination handling
3. **User Experience**: Clean JSON output, Vietnamese error messages
4. **Reliability**: Timeout protection, graceful failure handling  
5. **Flexibility**: Multi-language support, configurable parameters
6. **Documentation**: Well-commented code, clear API descriptions
7. **Maintainable**: Centralized configuration, no magic numbers

## üîç TECHNICAL NOTES

### Dependencies
- `requests` - HTTP client for Google API calls
- `mcp.server.fastmcp` - MCP server framework
- Standard library: `json`, `typing`, `urllib.parse`

### API Limitations
- Google Custom Search: 10 results per request
- Tool implements pagination for up to 30 results
- Respect for API rate limits and quotas

### Code Quality
- Type hints throughout codebase  
- Comprehensive docstrings
- Error handling at all levels
- Clean separation of concerns

## üîß CODE QUALITY IMPROVEMENTS (August 2025)

### Constants Centralization Completed
‚úÖ **DRY Principle**: Eliminated magic numbers, centralized config in `constants.py`  
‚úÖ **Maintainability**: Easy customization via configuration files  
‚úÖ **Backward Compatible**: Zero functional changes, improved code structure

### Web Fetch Tool - Verified Production Ready  
‚úÖ **Content Extraction**: HTML, JSON, plain text support v·ªõi BeautifulSoup  
‚úÖ **Batch Processing**: Multiple URLs v·ªõi error handling per URL  
‚úÖ **Quality Output**: Title, description, content, links v·ªõi word counts  
‚úÖ **Real-world Success**: Medium articles, JSON APIs, plain text processing

## üéØ COMPLETE WORKFLOW DEMO (August 2025)

### Search ‚Üí Fetch Pipeline Verification
**üîç Demo Scenario**: TypeScript 5.6 research workflow

**Phase 1 - Web Search Tool:**
- **Query**: "TypeScript 5.6 new features type safety improvements 2025"
- **Results**: 15 high-quality articles from authoritative sources
- **Top Source**: Medium article by Onix React team

**Phase 2 - Web Fetch Tool:**
- **Target URL**: https://medium.com/@onix_react/whats-new-in-typescript-5-6-99ba92b8c503
- **Extraction Success**: 1,173 words of detailed TypeScript content
- **Metadata**: Professional title, description, 16 related links
- **Content Quality**: Complete article about TypeScript 5.6 features

### Production Integration Verified
‚úÖ **Complete Pipeline**: Search (15 results) ‚Üí Fetch (1,173 words) ‚Üí Extract (16 links)  
‚úÖ **Real-world Content**: Medium TypeScript 5.6 article successfully processed  
‚úÖ **Zero Failures**: Error-free operation across complete workflow  
‚úÖ **Research Value**: From search query to comprehensive content analysis

---
**Last Updated**: August 2025 (Extreme Scale Optimization Completed)
**Status**: Production Ready - EXTREME SCALE Web Research Suite
**Capabilities**: 500MB content, 2M chars extraction, 50 URLs batch, context-optimized
**Next Milestone**: AI-powered content analysis and intelligent document processing
